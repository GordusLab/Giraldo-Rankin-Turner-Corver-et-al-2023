{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np, matplotlib.pyplot as plt, pandas as pd, \\\n",
    "    re, joblib as jl, statsmodels.stats, statsmodels.stats.multitest, datetime\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One of: '1-human', '2-human', 'CO2', '6-human'\n",
    "#EXPERIMENT = 'CO2'\n",
    "\n",
    "# One of: 'LANDINGS' (all EXPERIMENTs), 'OCCUPANCY' (6-human only)\n",
    "#MODE = 'LANDINGS'\n",
    "\n",
    "# One of: False, True\n",
    "#USE_ABSOLUTE_COUNTS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data (1-human, 2-human, CO2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataMisc():\n",
    "    fname = 'data_raw/data_AllC.csv'\n",
    "    # Load data\n",
    "    data = pd.read_csv(fname).T.reset_index().iloc[:, 1:]\n",
    "    # Change column names\n",
    "    data.columns = ['landing_count', 'experiment', 'participant_name', 'participant_position', 'experiment_date']\n",
    "    # Convert participant name\n",
    "    participants1human = data.loc[data.experiment=='1-human', 'participant_name'].unique().tolist()\n",
    "    participants2human = data.loc[data.experiment=='2-human', 'participant_name'].unique().tolist()\n",
    "    participantsCO2 = data.loc[data.experiment=='CO2', 'participant_name'].unique().tolist()\n",
    "    # -- Map indices\n",
    "    data.loc[data.experiment=='1-human', 'participant_id'] = [\n",
    "        participants1human.index(x) for x in data.loc[data.experiment=='1-human', 'participant_name']]\n",
    "    data.loc[data.experiment=='2-human', 'participant_id'] = [\n",
    "        participants2human.index(x) for x in data.loc[data.experiment=='2-human', 'participant_name']]\n",
    "    data.loc[data.experiment=='CO2', 'participant_id'] = [\n",
    "        participantsCO2.index(x) for x in data.loc[data.experiment=='CO2', 'participant_name']]\n",
    "    data.participant_id = data.participant_id.astype(int)\n",
    "    # Remember mapping from participant id to participant name\n",
    "    participantNames = {}\n",
    "    for exp in ['1-human', '2-human', 'CO2']:\n",
    "        participantNames[exp] = {}\n",
    "        for pid in data[(data.experiment==exp)].participant_id.unique():\n",
    "            correspondingName = data[(data.experiment==exp)&(\n",
    "                data.participant_id==pid)].participant_name.unique()\n",
    "            assert(len(correspondingName) == 1)\n",
    "            participantNames[exp][int(pid)] = correspondingName[0]\n",
    "    # Convert data types\n",
    "    data.landing_count = data.landing_count.astype(int)\n",
    "    # Make compatible with 6-human analysis by creating a start/end row for each landing\n",
    "    newdata = []\n",
    "    for ri, r in data.iterrows():\n",
    "        # Add 0-duration trajectory to day/position pair\n",
    "        newdata.append((r.experiment, r.experiment_date, \n",
    "                        r.participant_position, r.participant_id, \n",
    "                        0, 0, 0, 2020))\n",
    "        newdata.append((r.experiment, r.experiment_date, \n",
    "                        r.participant_position, r.participant_id, \n",
    "                        r.landing_count, 0, 0, 2020))\n",
    "        # Add landings individually\n",
    "        for landing_id in range(r.landing_count):\n",
    "            for frame_rel in [0, 1]:\n",
    "                newdata.append((r.experiment, r.experiment_date, \n",
    "                                r.participant_position, r.participant_id, \n",
    "                                1 + landing_id, frame_rel, frame_rel, 2020))\n",
    "            landing_id += 1\n",
    "    newdata = pd.DataFrame(newdata, columns=[\n",
    "        'experiment', 'experiment_date', 'participant_position', 'participant_id', \n",
    "        'landing_id', 'frame_rel', 'frame', 'experiment_year'])\n",
    "    # Subset to requested experiment\n",
    "    newdata = newdata[newdata.experiment == EXPERIMENT].reset_index()\n",
    "    # Construct assigned placement dictionary\n",
    "    personAssignments = {}\n",
    "    for _d in data.experiment_date.unique():\n",
    "        for _p in data.participant_position.unique():\n",
    "            # Retrieve participant at this position on this day\n",
    "            partid = data.participant_id[(data.experiment == EXPERIMENT)&(\n",
    "                data.experiment_date==_d)&(data.participant_position==_p)].values\n",
    "            if partid.size > 0:\n",
    "                if _d not in personAssignments:\n",
    "                    personAssignments[_d] = {}\n",
    "                personAssignments[_d][int(_p)] = partid[0]\n",
    "    # Assign back to 'data' variable name\n",
    "    return newdata, personAssignments, participantNames[EXPERIMENT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data (6-human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData6human():\n",
    "    # Specify source data file\n",
    "    fname = 'data_raw/tracking-predictions-aggregated-startendonly-filtered-50_10_20_0_20.csv'\n",
    "    \n",
    "    # Read 2022 data\n",
    "    data = pd.read_csv(fname)\n",
    "    data = data[data.experiment_year == 2022]\n",
    "    data = data.loc[:, ['experiment_year', 'experiment_date', 'participant_position', \n",
    "        'landing_id', 'frame_rel', 'frame', 'x', 'y']]\n",
    "    data = data[~data.experiment_date.isin(['04-07-2022', '04-14-2022'])]\n",
    "\n",
    "    # Parse position index integer from participant_position\n",
    "    data.loc[:, 'position_id'] = [int(re.search('[0-9]+', x).group(0)) for x in data.participant_position]\n",
    "    \n",
    "    # Look up what person was at each position\n",
    "    personAssignments = {}\n",
    "    newDate = None\n",
    "    personAssignmentsRaw = pd.read_excel('data_raw/human_positions.xlsx', header=None).values\n",
    "    for row in personAssignmentsRaw:\n",
    "        if isinstance(row[0], datetime.datetime):\n",
    "            newDate = row[0]\n",
    "        elif str(row[0]).isnumeric():\n",
    "            position, human = row[:2]\n",
    "            newDateStr = newDate.strftime('%m-%d-%Y')\n",
    "            if newDateStr in personAssignments:\n",
    "                personAssignments[newDateStr][position] = human\n",
    "            else:\n",
    "                personAssignments[newDateStr] = {position: human}\n",
    "    \n",
    "    # Get participant name strings\n",
    "    participantNames = {}\n",
    "    for pid in np.unique(np.hstack([list(personAssignments[x].values()) for x in personAssignments])):\n",
    "        participantNames[pid] = 'Human {}'.format(pid)\n",
    "    \n",
    "    # Convert position index and day to person index\n",
    "    data.loc[:, 'participant_id'] = [personAssignments[_d][_p] for _p, _d in zip(\n",
    "        data.position_id, data.experiment_date)]\n",
    "    \n",
    "    # Set experiment\n",
    "    data.loc[:, 'experiment'] = '6-human'\n",
    "    \n",
    "    # Done\n",
    "    return data, personAssignments, participantNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getData = getData6human if EXPERIMENT == '6-human' else getDataMisc\n",
    "\n",
    "data, personAssignments, participantNames = getData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test null hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeLandingStatistics(data, shufflePositions=False, \n",
    "        locationWeights=None, mode='', personAssignments=None):\n",
    "    # Compute landing durations\n",
    "    dataAgg = data.groupby([\n",
    "        'experiment_year', 'experiment_date', 'participant_position', \n",
    "        'landing_id']).agg(['min', 'max'])\n",
    "    dataAgg.columns = ['_'.join(col).strip() for col in dataAgg.columns.values]\n",
    "    dataAgg.loc[:, 'duration'] = dataAgg.frame_max - dataAgg.frame_min\n",
    "    dataAgg.loc[:, 'duration_rel'] = dataAgg.frame_rel_max - dataAgg.frame_rel_min\n",
    "    dataAgg = dataAgg.reset_index()\n",
    "    dataAgg.head()\n",
    "    \n",
    "    # Create score column that is either fixed per trajectory (1), or set to duration\n",
    "    if mode == 'OCCUPANCY':\n",
    "        if EXPERIMENT == '6-human':\n",
    "            dataAgg.loc[:, 'weight'] = dataAgg.duration\n",
    "        else:\n",
    "            # No duration data analyzed for other experiments, do not allow this config combination\n",
    "            raise Exception('Occupancy duration only analyzed for 6-human experiment.')\n",
    "    elif mode == 'LANDINGS':\n",
    "        if EXPERIMENT == '6-human':\n",
    "            dataAgg.loc[:, 'weight'] = 1.0\n",
    "        else:\n",
    "            # NOTE: Only for CO2/1-human/2-human data:\n",
    "            #       The duration is set to either 1, or set to 0 for one \"fake\" landing per \n",
    "            #       experimental day/position. This facilitates analysis. Note we are still \n",
    "            #       counting landings here, not measuring occupancy.\n",
    "            dataAgg.loc[:, 'weight'] = dataAgg.duration\n",
    "    else:\n",
    "        raise Exception('Invalid analysis mode')\n",
    "    \n",
    "    # Compute number of landings by day\n",
    "    dataAgg.loc[:, 'total_landings_by_day'] = dataAgg.groupby([\n",
    "        'experiment_year', 'experiment_date']).transform('sum').weight.astype(float)\n",
    "\n",
    "    # Parse position index integer from participant_position\n",
    "    dataAgg.loc[:, 'position_id'] = [int(re.search('[0-9]+', x).group(0)) for x in dataAgg.participant_position]\n",
    "\n",
    "    # Shuffle?\n",
    "    if shufflePositions and locationWeights is not None:\n",
    "        for p in dataAgg.experiment_date.unique():\n",
    "            # Randomly divide landings from day X according to overall location biases\n",
    "            dataAgg.loc[dataAgg.experiment_date==p, 'position_id'] = \\\n",
    "                np.random.choice(locationWeights.index.values, p=locationWeights.values, replace=True,\n",
    "                    size=(dataAgg.experiment_date==p).sum())\n",
    "        \n",
    "    # Compute number of landings by individual/position for each day\n",
    "    dataAgg.loc[:, 'position_landings_by_day'] = dataAgg.groupby([\n",
    "        'experiment_year', 'experiment_date', 'position_id']).transform('sum').weight.astype(float)\n",
    "\n",
    "    # Compute percent landings by individual/position for each day\n",
    "    dataAgg.loc[:, 'percent_landings_'] = 100 * dataAgg.position_landings_by_day / \\\n",
    "        dataAgg.total_landings_by_day\n",
    "    \n",
    "    # In regular mode, we compute landing differences as percentage landing differences.\n",
    "    # If USE_ABSOLUTE_COUNTS is enabled, the landing differences are displayed as absolute \n",
    "    # landing counts (though the column name remains 'percent_landings'). However, even \n",
    "    # if USE_ABSOLUTE_COUNTS is enabled, the biases for each position (used to simulate \n",
    "    # the null hypothesis) will still be based on landing percentages.\n",
    "    if USE_ABSOLUTE_COUNTS:\n",
    "        dataAgg.loc[:, 'percent_landings'] = dataAgg.position_landings_by_day\n",
    "    else:\n",
    "        dataAgg.loc[:, 'percent_landings'] = dataAgg.loc[:, 'percent_landings_']\n",
    "\n",
    "    # Convert position index and day to person index\n",
    "    dataAgg.loc[:, 'participant_id'] = [personAssignments[_d][_p] for _p, _d in zip(\n",
    "        dataAgg.position_id, dataAgg.experiment_date)]\n",
    "\n",
    "    # Get landing statistics only (no trajectory data)\n",
    "    dataLandings = dataAgg.loc[dataAgg.landing_id==0, [\n",
    "        'experiment_date', 'percent_landings', 'percent_landings_', 'participant_id', \n",
    "            'position_id', 'total_landings_by_day']].reset_index(drop=True)\n",
    "    \n",
    "    # Get mean percent landings by person\n",
    "    dataLandings.loc[:, 'percent_landings_mean_participant'] = dataLandings.groupby(\n",
    "        'participant_id').transform('mean').percent_landings_\n",
    "\n",
    "    # Get mean percent landings by position\n",
    "    dataLandings.loc[:, 'percent_landings_mean_position'] = dataLandings.groupby(\n",
    "        'position_id').transform('mean').percent_landings_\n",
    "    \n",
    "    # Sort by participant\n",
    "    dataLandingsSortedParticipants = dataLandings.sort_values(\n",
    "        'percent_landings_mean_participant', ascending=False)\n",
    "\n",
    "    # Sort by position\n",
    "    dataLandingsSortedPositions = dataLandings.sort_values(\n",
    "        'percent_landings_mean_position', ascending=False)\n",
    "\n",
    "    # Get participant ranking\n",
    "    participantRanking = dataLandings.groupby(\n",
    "        'participant_id').first().percent_landings_mean_participant.rank(ascending=False)\n",
    "\n",
    "    # Get position ranking\n",
    "    positionRanking = dataLandings.groupby(\n",
    "        'position_id').first().percent_landings_mean_position.rank(ascending=False)\n",
    "    \n",
    "    # Return results\n",
    "    return dataAgg, dataLandings, dataLandingsSortedParticipants, \\\n",
    "        dataLandingsSortedPositions, participantRanking, positionRanking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mean-based ranking of participants\n",
    "data, personAssignments, participantNames = getData()\n",
    "dataAgg, dataLandings, dataLandingsSortedParticipants, dataLandingsSortedPositions, \\\n",
    "    participantRanking, positionRanking = computeLandingStatistics(\n",
    "        data, shufflePositions=False, mode=MODE, personAssignments=personAssignments)\n",
    "participantsSorted = dataLandingsSortedParticipants.participant_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomization test for 5000 (location-weighted) random trajectories\n",
    "def getRankings(mode):\n",
    "    data, personAssignments, participantNames = getData()\n",
    "    \n",
    "    # Compute location weights\n",
    "    dataLandings = computeLandingStatistics(\n",
    "        data, shufflePositions=False, mode=mode, personAssignments=personAssignments)[1]\n",
    "    weightsPositions = dataLandings.groupby(\n",
    "        'position_id').sum().percent_landings_mean_position.copy()\n",
    "    weightsPositions = weightsPositions / weightsPositions.sum()\n",
    "    \n",
    "    # Compute shuffled rankings\n",
    "    participantRankings = []\n",
    "    for k in range(50):\n",
    "        print(k)\n",
    "        dataAgg, dataLandings, dataLandingsSortedParticipants, dataLandingsSortedPositions, \\\n",
    "            participantRanking, positionRanking = computeLandingStatistics(\n",
    "                data, shufflePositions=True, locationWeights=weightsPositions, \n",
    "                mode=mode, personAssignments=personAssignments)\n",
    "        participantRankings.append(dataLandings.groupby('participant_id').mean().percent_landings)\n",
    "    return participantRankings\n",
    "\n",
    "# Run in parallel\n",
    "participantRankingsL = jl.Parallel(n_jobs=58)(jl.delayed(\n",
    "    getRankings)(MODE) for i in tqdm(range(100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-shuffled rankings\n",
    "participantRankingsTrueL = computeLandingStatistics(\n",
    "    data, shufflePositions=False, mode=MODE, personAssignments=personAssignments)[1]\n",
    "participantRankingsTrueL = participantRankingsTrueL.groupby('participant_id').mean().percent_landings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for getting landing % difference\n",
    "def getLandingDiff(x, pA, pB):\n",
    "    vA, vB = 0, 0\n",
    "    if pA in x.index:\n",
    "        vA = x.loc[pA]\n",
    "    if pB in x.index:\n",
    "        vB = x.loc[pB]\n",
    "    return vA - vB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomizationTest(participantsSorted, participantRankings, participantRankingsTrue):\n",
    "    numDts = 8\n",
    "    pvals = {}\n",
    "    for dti, dt in enumerate(range(1, 1 + numDts)):\n",
    "        for c in range(len(participantsSorted) - dt):\n",
    "            pA = participantsSorted[c]\n",
    "            pB = participantsSorted[c+dt]\n",
    "\n",
    "            randvals = [getLandingDiff(x, pA, pB) for y in participantRankings for x in y]\n",
    "            trueval = getLandingDiff(participantRankingsTrue, pA, pB)\n",
    "            pvals[(pA, pB)] = (np.mean(randvals > trueval), randvals, trueval)\n",
    "    \n",
    "    adj = statsmodels.stats.multitest.multipletests(\n",
    "        [pvals[x][0] for x in pvals], alpha=0.05, method='fdr_bh')[1]\n",
    "    \n",
    "    npvals = {}\n",
    "    for xi, x in enumerate([x for x in pvals]):\n",
    "        npvals[x] = (pvals[x][0], pvals[x][1], pvals[x][2], adj[xi])\n",
    "    \n",
    "    return npvals\n",
    "\n",
    "testsL = randomizationTest(participantsSorted, participantRankingsL, participantRankingsTrueL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for measure in ['landings', ]:\n",
    "    plottingData = []\n",
    "\n",
    "    tests = testsL\n",
    "    numDts = participantsSorted.size - 1\n",
    "\n",
    "    # Embed metadata such as participant plot ranking and names\n",
    "    for participantID in participantNames:\n",
    "        plottingData.append((\n",
    "            measure, 'name_and_ranking', participantID, -1, \n",
    "            0, 0, 0, 0, \n",
    "            participantNames[participantID],\n",
    "            np.argwhere(np.array(participantsSorted) == participantID)[0, 0]\n",
    "        ))\n",
    "    \n",
    "    # Determine min/max range across all pairings\n",
    "    mn = np.min([np.min(tests[x][1]) for x in tests])\n",
    "    mx = np.max([np.max(tests[x][1]) for x in tests])\n",
    "\n",
    "    for dti, dt in enumerate(range(1, 1 + numDts)):\n",
    "        for c in range(len(participantsSorted) - dt):\n",
    "            pA = participantsSorted[c]\n",
    "            pB = participantsSorted[c+dt]\n",
    "            \n",
    "            pval, randvals, trueval, pvaladj = tests[(pA, pB)]\n",
    "                        \n",
    "            # Compute histogram for this pairing\n",
    "            pval, randvals, trueval, pvaladj = tests[(pA, pB)]\n",
    "            counts, edges = np.histogram(randvals, bins=100, range=(mn, mx))\n",
    "            bins = edges[1:] * 0.5 + edges[:edges.size-1] * 0.5\n",
    "            \n",
    "            for binn, count in zip(bins, counts):\n",
    "                plottingData.append((measure, 'randomized', pA, pB, binn, int(\n",
    "                    count), pval, pvaladj, '', -1))\n",
    "            plottingData.append((measure, 'observed', pA, pB, trueval, \n",
    "                1, pval, pvaladj, '', -1))\n",
    "\n",
    "    plottingData = pd.DataFrame(plottingData, columns=['measure', 'randomized_or_observed', 'human_or_stim_A', \n",
    "        'human_or_stim_B', 'difference_histogram_bin', 'count', 'pval_unadj', 'pval_adj', \n",
    "        'human_or_stim_name', 'human_or_stim_ranking'])\n",
    "\n",
    "    plottingData.to_csv('Landings_Permutation_Test_{}_{}_{}.csv'.format(\n",
    "            EXPERIMENT, MODE, 'absolutecounts' if USE_ABSOLUTE_COUNTS else 'percentages'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the code below runs with only CSV data by clearing all previously-defined variables\n",
    "%reset_selective -f ^(?!EXPERIMENT$|MODE$|USE_ABSOLUTE_COUNTS$).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, matplotlib.pyplot as plt, pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plottingData = pd.read_csv('Landings_Permutation_Test_{}_{}_{}.csv'.format(\n",
    "    EXPERIMENT, MODE, 'absolutecounts' if USE_ABSOLUTE_COUNTS else 'percentages'))\n",
    "plottingData.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover participant sorting from CSV data\n",
    "srt = plottingData[plottingData.randomized_or_observed == 'name_and_ranking'].groupby('human_or_stim_A').first()\n",
    "stims = srt.index\n",
    "stimsR = srt.human_or_stim_ranking\n",
    "stimsN = srt.human_or_stim_name\n",
    "\n",
    "participantsSorted = [-1 for i in range(len(stims))]\n",
    "participantNames = {}\n",
    "\n",
    "for s, r, n in zip(stims, stimsR, stimsN):\n",
    "    participantsSorted[r] = int(s)\n",
    "    participantNames[s] = n\n",
    "\n",
    "participantsSorted = np.array(participantsSorted)\n",
    "participantsSorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotRankingTests(plottingData, MODE):\n",
    "    numDts = participantsSorted.size - 1\n",
    "\n",
    "    fig, ax = plt.subplots(numDts, len(participantsSorted) - 1, figsize=(14, 1.75 * numDts), facecolor='white')\n",
    "    \n",
    "    if ax.ndim == 1:\n",
    "        ax = np.array([ax,]).T\n",
    "        print(ax.shape)\n",
    "    \n",
    "    for dti, dt in enumerate(range(1, 1 + numDts)):\n",
    "        for c in range(len(participantsSorted) - dt):\n",
    "            pA = participantsSorted[c]\n",
    "            pB = participantsSorted[c+dt]\n",
    "            \n",
    "            # Get data for plotting\n",
    "            d = plottingData.loc[(\n",
    "                plottingData.human_or_stim_A==pA)&(\n",
    "                plottingData.human_or_stim_B==pB)&(\n",
    "                plottingData.randomized_or_observed=='randomized'), [\n",
    "                    'difference_histogram_bin', 'count', 'pval_adj']].values\n",
    "            bins, counts, pvaladj = d[:, 0], d[:, 1], d[0, 2]\n",
    "            \n",
    "            trueval = plottingData.loc[(\n",
    "                plottingData.human_or_stim_A==pA)&(\n",
    "                plottingData.human_or_stim_B==pB)&(\n",
    "                plottingData.randomized_or_observed=='observed'), [\n",
    "                    'difference_histogram_bin', ]].values[0, 0]\n",
    "            \n",
    "            # plot\n",
    "            ax[dti, c].fill_between(bins, counts, color='#666666')\n",
    "            ax[dti, c].axvline(trueval, c='red')\n",
    "            \n",
    "            ax[dti, c].set_title('#{} vs. #{}'.format(\n",
    "                participantNames[pA], participantNames[pB]), size=10)\n",
    "            \n",
    "            ax[dti, c].text(0.05, 0.95, (\n",
    "                'p={:.2E}' if (pvaladj > 1e-12 and pvaladj < 0.01) else 'p={:.3f}').format(pvaladj),\n",
    "                 horizontalalignment='left',\n",
    "                 verticalalignment='top',\n",
    "                 transform = ax[dti, c].transAxes, \n",
    "                 fontsize=12)\n",
    "\n",
    "            if c == 0:\n",
    "                ax[dti, c].set_ylabel('Occurrences')\n",
    "            else:\n",
    "                ax[dti, c].yaxis.set_ticklabels([])\n",
    "            if c == len(participantsSorted) - dt - 1:\n",
    "                ax[dti, c].set_xlabel('{} {}\\nDifference\\n(First - Second)'.format(\n",
    "                    'Landing' if MODE == 'LANDINGS' else 'Occupancy',\n",
    "                    'Percentage' if not USE_ABSOLUTE_COUNTS else 'Count'))\n",
    "            else:\n",
    "                ax[dti, c].xaxis.set_ticklabels([])\n",
    "                \n",
    "            # Set Y axis to same scale everywhere\n",
    "            ax[dti, c].set_ylim(0, np.percentile(plottingData.loc[:, 'count'].values, 98))\n",
    "            \n",
    "            # Set X axis to shared range\n",
    "            mn, mx = plottingData.loc[(plottingData.human_or_stim_A==pA)&(\n",
    "                plottingData.randomized_or_observed.isin(\n",
    "                    ['randomized', 'observed'])), 'difference_histogram_bin'].agg(['min', 'max']).values\n",
    "            ax[dti, c].set_xlim(mn, mx)\n",
    "        \n",
    "        for c in range(len(participantsSorted) - dt, len(participantsSorted) - 1):\n",
    "            try:\n",
    "                ax[dti, c].set_axis_off()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(left=0.06, bottom=0.1, right=0.94, top=0.94, wspace=0.25, hspace=0.25)\n",
    "    fig.savefig('Landings_Permutation_Test_{}_{}_{}.pdf'.format(\n",
    "        EXPERIMENT, MODE, 'absolutecounts' if USE_ABSOLUTE_COUNTS else 'percentages'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotRankingTests(plottingData, MODE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
